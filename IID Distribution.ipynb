{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee09c5d-f427-4cf5-bd91-ae0f80ae96c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 class distribution: {0: 84, 1: 88, 2: 72, 3: 72, 4: 64, 5: 74, 6: 65, 7: 54, 8: 72, 9: 61} (Total: 706)\n",
      "Client 1 class distribution: {0: 76, 1: 89, 2: 63, 3: 77, 4: 79, 5: 63, 6: 69, 7: 87, 8: 71, 9: 71} (Total: 745)\n",
      "Client 2 class distribution: {0: 130, 1: 159, 2: 142, 3: 142, 4: 142, 5: 107, 6: 134, 7: 143, 8: 131, 9: 128} (Total: 1358)\n",
      "Client 3 class distribution: {0: 16, 1: 18, 2: 17, 3: 15, 4: 11, 5: 16, 6: 9, 7: 21, 8: 15, 9: 20} (Total: 158)\n",
      "Client 4 class distribution: {0: 101, 1: 104, 2: 97, 3: 97, 4: 71, 5: 98, 6: 89, 7: 117, 8: 92, 9: 95} (Total: 961)\n",
      "\n",
      "Selected clients for this round: [52, 94, 64, 99, 75, 37, 93, 15, 35, 96, 14, 76, 40, 62, 5, 61, 33, 49, 86, 87]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "\n",
    "# Load MNIST training data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Parameters\n",
    "num_clients = 100\n",
    "total_samples = len(mnist_train)  # 60,000\n",
    "\n",
    "# Extract labels and indices\n",
    "all_indices = np.arange(total_samples)\n",
    "labels = np.array(mnist_train.targets)\n",
    "np.random.shuffle(all_indices)\n",
    "\n",
    "# Use Dirichlet to sample varying client sizes (sums to total_samples)\n",
    "proportions = np.random.dirichlet(alpha=np.ones(num_clients), size=1)[0]\n",
    "client_sizes = (proportions * total_samples).astype(int)\n",
    "\n",
    "# Fix rounding issue\n",
    "diff = total_samples - np.sum(client_sizes)\n",
    "client_sizes[np.argmax(client_sizes)] += diff\n",
    "\n",
    "# Step 1: Assign samples randomly while preserving global distribution\n",
    "client_indices = defaultdict(list)\n",
    "start = 0\n",
    "for i in range(num_clients):\n",
    "    end = start + client_sizes[i]\n",
    "    client_indices[i] = all_indices[start:end].tolist()\n",
    "    start = end\n",
    "\n",
    "# Step 2: Create Subset datasets\n",
    "client_datasets = [Subset(mnist_train, client_indices[i]) for i in range(num_clients)]\n",
    "\n",
    "# Debug: Show class distribution for first 5 clients\n",
    "for i in range(5):\n",
    "    client_labels = [mnist_train.targets[idx].item() for idx in client_datasets[i].indices]\n",
    "    label_count = dict(sorted(Counter(client_labels).items()))\n",
    "    print(f\"Client {i} class distribution: {label_count} (Total: {len(client_datasets[i])})\")\n",
    "\n",
    "# Example: Randomly choose 20 clients for training in a round\n",
    "selected_clients = random.sample(range(num_clients), 20)\n",
    "print(f\"\\nSelected clients for this round: {selected_clients}\")\n",
    "selected_datasets = [client_datasets[i] for i in selected_clients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc32fe-af56-4340-866f-d62a51b4fd89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
