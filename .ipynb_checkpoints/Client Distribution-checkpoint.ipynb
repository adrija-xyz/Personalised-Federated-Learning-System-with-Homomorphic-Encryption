{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d158650-3806-427e-a7dc-ddd18a03e7f3",
   "metadata": {},
   "source": [
    "## IID (Independent and Identically Distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5cc2a3-5d81-45f8-ad1e-05453179a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80912a49-4768-4f45-96da-536953546a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3612435-b2d1-4803-b3d0-2bdb33b4c7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 class distribution: {0: 81, 1: 104, 2: 95, 3: 80, 4: 88, 5: 82, 6: 98, 7: 105, 8: 80, 9: 96} (Total: 909)\n",
      "Client 1 class distribution: {0: 150, 1: 175, 2: 138, 3: 135, 4: 132, 5: 120, 6: 148, 7: 166, 8: 133, 9: 150} (Total: 1447)\n",
      "Client 2 class distribution: {0: 39, 1: 36, 2: 45, 3: 33, 4: 54, 5: 36, 6: 35, 7: 30, 8: 45, 9: 40} (Total: 393)\n",
      "Client 3 class distribution: {0: 61, 1: 84, 2: 80, 3: 77, 4: 81, 5: 81, 6: 82, 7: 68, 8: 70, 9: 73} (Total: 757)\n",
      "Client 4 class distribution: {0: 54, 1: 79, 2: 62, 3: 47, 4: 49, 5: 59, 6: 53, 7: 55, 8: 56, 9: 56} (Total: 570)\n",
      "Client 5 class distribution: {0: 12, 1: 26, 2: 33, 3: 29, 4: 17, 5: 22, 6: 17, 7: 23, 8: 22, 9: 15} (Total: 216)\n",
      "Client 6 class distribution: {1: 2, 2: 2, 3: 1, 4: 1, 5: 1, 8: 2} (Total: 9)\n",
      "Client 7 class distribution: {0: 13, 1: 25, 2: 28, 3: 18, 4: 24, 5: 22, 6: 16, 7: 19, 8: 17, 9: 18} (Total: 200)\n",
      "Client 8 class distribution: {0: 21, 1: 24, 2: 31, 3: 30, 4: 23, 5: 16, 6: 25, 7: 28, 8: 24, 9: 22} (Total: 244)\n",
      "Client 9 class distribution: {0: 115, 1: 154, 2: 121, 3: 121, 4: 127, 5: 136, 6: 123, 7: 109, 8: 122, 9: 127} (Total: 1255)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Load MNIST training data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Parameters\n",
    "num_clients = 10\n",
    "total_samples = 6000\n",
    "\n",
    "# Extract labels\n",
    "labels = np.array(mnist_train.targets)\n",
    "\n",
    "# Step 1: Sample 6000 indices from the entire dataset to preserve global distribution\n",
    "all_indices = np.arange(len(labels))\n",
    "np.random.shuffle(all_indices)\n",
    "\n",
    "# Choose 6000 samples\n",
    "selected_indices = all_indices[:total_samples]\n",
    "selected_labels = labels[selected_indices]\n",
    "\n",
    "# Step 2: Randomly assign samples to clients (with varying sizes)\n",
    "client_indices = defaultdict(list)\n",
    "\n",
    "# Generate random proportions for each client (but sum to 1)\n",
    "proportions = np.random.dirichlet(np.ones(num_clients), size=1)[0]\n",
    "client_sizes = (proportions * total_samples).astype(int)\n",
    "\n",
    "# Fix rounding issue to ensure exactly 6000 samples\n",
    "diff = total_samples - np.sum(client_sizes)\n",
    "client_sizes[np.argmax(client_sizes)] += diff\n",
    "\n",
    "# Now split selected_indices into those sizes\n",
    "start = 0\n",
    "for client_id, size in enumerate(client_sizes):\n",
    "    client_indices[client_id] = selected_indices[start:start + size].tolist()\n",
    "    start += size\n",
    "\n",
    "# Create Subset datasets for each client\n",
    "client_datasets = [Subset(mnist_train, client_indices[i]) for i in range(num_clients)]\n",
    "\n",
    "# Debug: show class distribution per client\n",
    "for i, dataset in enumerate(client_datasets):\n",
    "    labels = [mnist_train.targets[idx].item() for idx in dataset.indices]\n",
    "    label_count = dict(sorted(Counter(labels).items()))\n",
    "    print(f\"Client {i} class distribution: {label_count} (Total: {len(dataset)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5cfa16-4fcf-441f-8510-8c24568bac0c",
   "metadata": {},
   "source": [
    "## Non-IID (Independent and Identically Distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b61e32-09aa-4ed0-9b5c-a1c5a0f33904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noniid_shards(dataset, num_clients=10, shards_per_client=2, total_samples=6000):\n",
    "    labels = np.array(dataset.targets)\n",
    "    data_indices = np.arange(len(labels))\n",
    "\n",
    "    # Step 1: Select 6000 samples only (preserve label proportions)\n",
    "    shuffled_indices = np.random.permutation(len(labels))\n",
    "    selected_indices = shuffled_indices[:total_samples]\n",
    "    selected_labels = labels[selected_indices]\n",
    "\n",
    "    # Step 2: Sort selected samples by label\n",
    "    sorted_indices = selected_indices[np.argsort(selected_labels)]\n",
    "\n",
    "    # Step 3: Create shards\n",
    "    num_shards = num_clients * shards_per_client\n",
    "    shard_size = total_samples // num_shards\n",
    "    shards = [sorted_indices[i * shard_size:(i + 1) * shard_size] for i in range(num_shards)]\n",
    "\n",
    "    # Step 4: Assign shards randomly to clients\n",
    "    np.random.shuffle(shards)\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "    \n",
    "    shard_idx = 0\n",
    "    for client_id in range(num_clients):\n",
    "        for _ in range(shards_per_client):\n",
    "            client_indices[client_id].extend(shards[shard_idx])\n",
    "            shard_idx += 1\n",
    "\n",
    "    # Step 5: Create Subset datasets\n",
    "    client_datasets = [Subset(dataset, indices) for indices in client_indices]\n",
    "\n",
    "    # Optional: Show label distributions\n",
    "    for i, dataset in enumerate(client_datasets):\n",
    "        lbls = [dataset.dataset.targets[idx].item() for idx in dataset.indices]\n",
    "        dist = dict(sorted(Counter(lbls).items()))\n",
    "        print(f\"Client {i} class distribution: {dist} (Total: {len(dataset)})\")\n",
    "\n",
    "    return client_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81a8495-ee8d-455c-a0ee-263e474a548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 class distribution: {2: 200, 3: 100, 5: 100, 6: 100, 7: 100} (Total: 600)\n",
      "Client 1 class distribution: {0: 80, 1: 20, 2: 200, 4: 200, 5: 12, 6: 88} (Total: 600)\n",
      "Client 2 class distribution: {1: 47, 2: 53, 4: 100, 5: 100, 8: 126, 9: 174} (Total: 600)\n",
      "Client 3 class distribution: {1: 200, 4: 100, 6: 100, 7: 200} (Total: 600)\n",
      "Client 4 class distribution: {6: 200, 8: 300, 9: 100} (Total: 600)\n",
      "Client 5 class distribution: {0: 200, 4: 76, 5: 124, 6: 100, 7: 100} (Total: 600)\n",
      "Client 6 class distribution: {0: 100, 2: 144, 3: 156, 5: 100, 6: 9, 7: 91} (Total: 600)\n",
      "Client 7 class distribution: {0: 100, 1: 200, 7: 151, 8: 149} (Total: 600)\n",
      "Client 8 class distribution: {3: 161, 4: 139, 5: 100, 9: 200} (Total: 600)\n",
      "Client 9 class distribution: {0: 100, 1: 200, 3: 200, 9: 100} (Total: 600)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "non_iid_clients = create_noniid_shards(mnist_train, num_clients=10, shards_per_client=6, total_samples=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb99bbf-e4c7-4fa4-b5e9-8f58ad090411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
